{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaPsPKqtyF5Yn6jHPmYX42",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seongjin1225/AI_School_9th_Final_Project_TEAM_3/blob/main/Unet_%EC%BD%94%EB%93%9C_ver2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmykhzWDtc-l"
      },
      "outputs": [],
      "source": [
        "!pip install -q segmentation_models_pytorch\n",
        "# !pip install -qU wandb\n",
        "!pip install -q scikit-learn==1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìö Import Libraries"
      ],
      "metadata": {
        "id": "lnPXXEC7trTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.options.plotting.backend = \"plotly\"\n",
        "import random\n",
        "from glob import glob\n",
        "import os, shutil\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "import time\n",
        "import copy\n",
        "import joblib\n",
        "from collections import defaultdict\n",
        "import gc\n",
        "from IPython import display as ipd\n",
        "from PIL import Image\n",
        "\n",
        "# visualization\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda import amp\n",
        "\n",
        "import timm\n",
        "\n",
        "# Albumentations for augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import rasterio\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# For colored terminal text\n",
        "from colorama import Fore, Back, Style\n",
        "c_  = Fore.GREEN\n",
        "sr_ = Style.RESET_ALL\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# For descriptive error messages\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "FnK6cMgytnku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìñ Data"
      ],
      "metadata": {
        "id": "f-1pEW-ct0Lu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data\n",
        "directory_path_train = '/content/drive/MyDrive/Final_Project/blood-vessel-segmentation/train'\n",
        "\n",
        "# ÌååÏùº Í≤ΩÎ°úÎ•º Î¶¨Ïä§Ìä∏ ÌòïÌÉúÎ°ú Ï†ÄÏû•ÌïòÎäî Ìï®Ïàò\n",
        "def list_files_in_directory(directory_path = directory_path_train):\n",
        "    direc = []\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for dire in dirs:\n",
        "            if dire in [\"labels\",\"images\"]:\n",
        "                continue\n",
        "            file_path = os.path.join(root, dire)\n",
        "            direc.append(file_path)\n",
        "    return direc\n",
        "\n",
        "train_folders = list_files_in_directory(directory_path_train)\n",
        "train_folders\n",
        "\n",
        "def count_total_img(folders = train_folders):\n",
        "    sub_f = [\"images\",\"labels\"]\n",
        "    path = []\n",
        "    total_files = []\n",
        "    for dire in folders:\n",
        "        for subf in sub_f:\n",
        "            if (dire == \"/content/drive/MyDrive/Final_Project/blood-vessel-segmentation/train/kidney_3_dense\") & (subf != \"labels\"):\n",
        "                continue\n",
        "            _dir = dire + \"/\" + subf\n",
        "            total_sample = len(os.listdir(_dir))\n",
        "            path.append(_dir)\n",
        "            total_files.append(total_sample)\n",
        "    obj = {\n",
        "        \"path\": path,\n",
        "        \"total_files\":total_files\n",
        "    }\n",
        "    return obj\n",
        "\n",
        "train_file_dir = count_total_img()\n",
        "\n",
        "folders = train_file_dir\n",
        "_paths = list(zip(folders['path'], folders['total_files']))\n",
        "\n",
        "\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "for path, total_files in _paths:\n",
        "    split_text = path.split(\"/\")\n",
        "\n",
        "    if 'labels' in split_text:\n",
        "        label_path = os.path.join(*split_text)\n",
        "        train_labels.extend(glob(f'/{label_path}/*.tif'))\n",
        "\n",
        "    if 'images' in split_text:\n",
        "        image_path = os.path.join(*split_text)\n",
        "        train_images.extend(glob(f'/{image_path}/*.tif'))\n",
        "\n",
        "    if 'kidney_3_dense' in split_text:\n",
        "        image_path = os.path.join(*split_text).replace('kidney_3_dense', 'kidney_3_sparse').replace('labels','images')\n",
        "        train_images.extend(glob(f'/{image_path}/*.tif')[:501])\n",
        "\n",
        "print(len(train_images))  # 7429\n",
        "print(len(train_labels))  # 7429\n",
        "\n",
        "\n",
        "# Test Data\n",
        "test_directory = '/content/drive/MyDrive/Final_Project/blood-vessel-segmentation/tetst'\n",
        "\n",
        "def list_files_in_directorys(directory_path = test_directory):\n",
        "    direc = []\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for dire in dirs:\n",
        "            if dire in [\"images\"]:\n",
        "                continue\n",
        "            file_path = os.path.join(root, dire)\n",
        "            direc.append(file_path)\n",
        "    return direc\n",
        "\n",
        "test_folders = list_files_in_directorys(test_directory)\n",
        "test_folders\n",
        "\n",
        "def count_total_imgs(folders = test_folders):\n",
        "    sub_f = [\"images\"]\n",
        "    path = []\n",
        "    total_files = []\n",
        "    for dire in folders:\n",
        "        for subf in sub_f:\n",
        "            _dir = dire + \"/\" + subf\n",
        "            total_sample = len(os.listdir(_dir))\n",
        "            path.append(_dir)\n",
        "            total_files.append(total_sample)\n",
        "    obj = {\n",
        "        \"path\": path,\n",
        "        \"total_files\":total_files\n",
        "    }\n",
        "    return obj\n",
        "\n",
        "test_file_dir = count_total_imgs()\n",
        "folders = test_file_dir\n",
        "_paths = list(zip(folders['path'], folders['total_files']))\n",
        "\n",
        "test_images = []\n",
        "\n",
        "for path, total_files in _paths:\n",
        "    split_text = path.split(\"/\")\n",
        "\n",
        "    if 'images' in split_text:\n",
        "        image_path = os.path.join(*split_text)\n",
        "        test_images.extend(glob(f'/{image_path}/*.tif'))\n",
        "\n",
        "print(len(test_images))\n",
        "\n",
        "df = pd.DataFrame(data={\"images\": train_images, 'masks' : train_labels})"
      ],
      "metadata": {
        "id": "t1zDyNUStu7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öôÔ∏è Configuration"
      ],
      "metadata": {
        "id": "3p3tp_fGt4_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    seed          = 101   # ÎûúÎç§ ÏãúÎìú ÏÑ§Ï†ï\n",
        "    debug         = False  # Ï†ÑÏ≤¥ ÌïôÏäµÏùÑ ÏúÑÌï¥ FalseÎ°ú\n",
        "    exp_name      = 'Baselinev2'  # Ïù¥Î¶Ñ\n",
        "    comment       = 'unet-efficientnet_b1-512x512'  # ÏΩîÎ©òÌä∏\n",
        "    model_name    = 'Unet'  # ÏÇ¨Ïö© Î™®Îç∏ Ïù¥Î¶Ñ\n",
        "    backbone      = 'efficientnet-b1'  # Î∞±Î≥∏(Backbone) Î™®Îç∏Ïùò Ïù¥Î¶Ñ\n",
        "    train_bs      = 16  # ÌõàÎ†® Î∞∞Ïπò ÏÇ¨Ïù¥Ï¶à\n",
        "    valid_bs      = train_bs*2  # Í≤ÄÏ¶ù Î∞∞Ïπò ÏÇ¨Ïù¥Ï¶à\n",
        "    val_split     = 0.2  # Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ÏÖã Î∂ÑÌï† ÎπÑÏú®\n",
        "    random_state  = 42\n",
        "    img_size      = [512, 512]  # Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞ ÏÑ§Ï†ï\n",
        "    epochs        = 5  # ÌõàÎ†® ÏóêÌè≠\n",
        "    lr            = 2e-3  # learning_rate\n",
        "    scheduler     = 'CosineAnnealingLR'\n",
        "    optimizers    ='adam'\n",
        "    min_lr        = 1e-6  # ÏµúÏÜå ÌïôÏäµÎ•†\n",
        "    T_max         = int(30000/train_bs*epochs)+50  # CosineAnnealingLR Ïä§ÏºÄÏ§ÑÎü¨Ïùò Ï£ºÍ∏∞ ÏÑ§Ï†ï\n",
        "    T_0           = 25   # CosineAnnealingWarmRestarts Ïä§ÏºÄÏ§ÑÎü¨Ïùò Ï£ºÍ∏∞ ÏÑ§Ï†ï\n",
        "    warmup_epochs = 0\n",
        "    wd            = 1e-6  # Í∞ÄÏ§ëÏπò Í∞êÏá† (Weight Decay) ÏÑ§Ï†ï\n",
        "    n_accumulate  = max(1, 32//train_bs)  # Í∑∏ÎûòÎîîÏñ∏Ìä∏ ÎàÑÏ†Å (Gradient Accumulation) ÏÑ§Ï†ï\n",
        "    n_fold        = 5   # K-Fold Cross ValidationÏùò Fold Ïàò ÏÑ§Ï†ï\n",
        "    num_classes   = 1  # ÌÅ¥ÎûòÏä§ Ïàò ÏÑ§Ï†ï (Ïù¥ÏßÑ Î∂ÑÎ•òÏóêÏÑúÎäî 1)\n",
        "    device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    loss_func     = \"DiceLoss\"\n"
      ],
      "metadata": {
        "id": "g695XuE4uFf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚ùó Reproducibility"
      ],
      "metadata": {
        "id": "PD85stMauI9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ÎûúÎç§ ÏãúÎìú ÏÑ§Ï†ïÌïòÎäî Ìï®Ïàò\n",
        "\n",
        "def set_seed(seed = 42):\n",
        "    '''ÎÖ∏Ìä∏Î∂Å Ï†ÑÏ≤¥Ïùò ÏãúÎìúÎ•º ÏÑ§Ï†ïÌïòÏó¨ Í≤∞Í≥ºÍ∞Ä Îß§Î≤à ÎèôÏùºÌïòÍ≤å ÎÇòÏò§ÎèÑÎ°ù\n",
        "    Ïù¥Í≤ÉÏùÄ Ïû¨ÌòÑÏÑ±ÏùÑ ÏúÑÌïú Í≤É'''\n",
        "    np.random.seed(seed)  # NumPy ÎùºÏù¥Î∏åÎü¨Î¶¨Ïùò ÎÇúÏàò ÏãúÎìú ÏÑ§Ï†ï\n",
        "    random.seed(seed)  # PythonÏùò Í∏∞Î≥∏ random Î™®ÎìàÏùò ÎÇúÏàò ÏãúÎìú ÏÑ§Ï†ï\n",
        "    torch.manual_seed(seed)  # PyTorchÏùò ÎÇúÏàò ÏãúÎìú ÏÑ§Ï†ï\n",
        "    torch.cuda.manual_seed(seed)  # PyTorchÏóêÏÑú CUDAÎ•º ÏÇ¨Ïö©Ìï† Îïå GPU ÎÇúÏàò ÏãúÎìú ÏÑ§Ï†ï\n",
        "\n",
        "    # CuDNN Î∞±ÏóîÎìúÏóêÏÑú Ïã§ÌñâÌï† Îïå Îëê Í∞ÄÏßÄ Ï∂îÍ∞Ä ÏòµÏÖòÏùÑ ÏÑ§Ï†ï\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # Ìï¥Ïãú ÏãúÎìúÎ•º Í≥†Ï†ïÍ∞íÏúºÎ°ú ÏÑ§Ï†ï\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    print('> SEEDING DONE')\n",
        "\n",
        "set_seed(CFG.seed)"
      ],
      "metadata": {
        "id": "r4Df4eoBuLNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî® Utility"
      ],
      "metadata": {
        "id": "XWaB88_cuMkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(path):\n",
        "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    img = np.tile(img[...,None], [1, 1, 3]) # gray to rgb\n",
        "    img = img.astype('float32') # original is uint16\n",
        "    mx = np.max(img)\n",
        "    if mx:\n",
        "        img/=mx # scale image to [0, 1]\n",
        "    return img\n",
        "\n",
        "def load_msk(path):\n",
        "    msk = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "    msk = msk.astype('float32')\n",
        "    msk/=255.0\n",
        "    return msk"
      ],
      "metadata": {
        "id": "jH_XmsyguQcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rle_decode(mask_rle, shape):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (height,width) of array to return\n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "\n",
        "    '''\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths\n",
        "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "    return img.reshape(shape)  # Needed to align to RLE direction\n",
        "\n",
        "\n",
        "# ref.: https://www.kaggle.com/stainsby/fast-tested-rle\n",
        "def rle_encode(img):\n",
        "    '''\n",
        "    img: numpy array, 1 - mask, 0 - background\n",
        "    Returns run length as string formated\n",
        "    '''\n",
        "    pixels = img.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)"
      ],
      "metadata": {
        "id": "Yz8whNgOuUCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåà Augmentations"
      ],
      "metadata": {
        "id": "f0HzVJj0uU1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = {\n",
        "    \"train\": A.Compose([\n",
        "        A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "#         A.VerticalFlip(p=0.5),\n",
        "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.05, rotate_limit=10, p=0.5),\n",
        "        A.OneOf([\n",
        "            A.GridDistortion(num_steps=5, distort_limit=0.05, p=1.0),\n",
        "# #             A.OpticalDistortion(distort_limit=0.05, shift_limit=0.05, p=1.0),\n",
        "            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n",
        "        ], p=0.25),\n",
        "        A.CoarseDropout(max_holes=8, max_height=CFG.img_size[0]//20, max_width=CFG.img_size[1]//20,\n",
        "                         min_holes=5, fill_value=0, mask_fill_value=0, p=0.5),\n",
        "        ], p=1.0),\n",
        "\n",
        "    \"valid\": A.Compose([\n",
        "        A.Resize(*CFG.img_size, interpolation=cv2.INTER_NEAREST),\n",
        "        ], p=1.0)\n",
        "}"
      ],
      "metadata": {
        "id": "2-0K7j76uWS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üçö Dataset"
      ],
      "metadata": {
        "id": "zAUlqDdeuXzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data={\"images\": train_images, 'masks' : train_labels})\n",
        "\n",
        "class BuildDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,img_paths, msk_paths=[], transforms=None):\n",
        "        self.img_paths = img_paths\n",
        "        self.msk_paths = msk_paths\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_paths)\n",
        "\n",
        "    def load_img(self, img_path):\n",
        "        return torch.mean(img_path, dim=1, keepdim=True)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path  = self.img_paths[index]\n",
        "        img = load_img(img_path)\n",
        "\n",
        "        if len(self.msk_paths)>0:\n",
        "            msk_path = self.msk_paths[index]\n",
        "            msk = load_msk(msk_path)\n",
        "\n",
        "            if self.transforms:\n",
        "                data = self.transforms(image=img, mask=msk)\n",
        "                img  = data['image']\n",
        "                msk  = data['mask']\n",
        "            img = np.transpose(img, (2, 0, 1))  # PyTorchÏóêÏÑúÎäî Channels x Height x WidthÎ°ú ÌëúÌòÑÌïòÎØÄÎ°ú Î≥ÄÍ≤Ω\n",
        "            return torch.tensor(img), torch.tensor(msk)\n",
        "        else:\n",
        "            orig_size = img.shape\n",
        "            if self.transforms:\n",
        "                data = self.transforms(image=img)\n",
        "                img  = data['image']\n",
        "            img = np.transpose(img, (2, 0, 1))\n",
        "            return torch.tensor(img), torch.tensor(np.array([orig_size[0], orig_size[1]]))"
      ],
      "metadata": {
        "id": "qNaOzGNnuZq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üç∞ DataLoader"
      ],
      "metadata": {
        "id": "ApwZ6sheub8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and validation sets\n",
        "train_df, valid_df = train_test_split(df, test_size=CFG.val_split, random_state=CFG.random_state)\n",
        "\n",
        "# Convert image and mask paths to absolute paths\n",
        "# train_df[\"images\"] = train_df[\"images\"].apply(lambda x: os.path.join(CFG.data_root, x))\n",
        "# train_df[\"masks\"] = train_df[\"masks\"].apply(lambda x: os.path.join(CFG.data_root, x))\n",
        "# valid_df[\"images\"] = valid_df[\"images\"].apply(lambda x: os.path.join(CFG.data_root, x))\n",
        "# valid_df[\"masks\"] = valid_df[\"masks\"].apply(lambda x: os.path.join(CFG.data_root, x))\n",
        "\n",
        "# Convert data frames to lists\n",
        "train_img_paths = train_df[\"images\"].values.tolist()\n",
        "train_msk_paths = train_df[\"masks\"].values.tolist()\n",
        "valid_img_paths = valid_df[\"images\"].values.tolist()\n",
        "valid_msk_paths = valid_df[\"masks\"].values.tolist()\n",
        "\n",
        "# Optionally, subsample for debugging\n",
        "# debug = TrueÏù∏ Í≤ΩÏö∞, Ï†úÌïúÎêú ÏñëÏùò Îç∞Ïù¥ÌÑ∞Îßå ÏÇ¨Ïö©ÌïòÎèÑÎ°ù Îç∞Ïù¥ÌÑ∞ Í≤ΩÎ°úÎì§ÏùÑ ÏûòÎùºÎÇ¥Îäî ÏΩîÎìú\n",
        "if CFG.debug:\n",
        "    train_img_paths = train_img_paths[:CFG.train_bs * 5]\n",
        "    train_msk_paths = train_msk_paths[:CFG.train_bs * 5]\n",
        "    valid_img_paths = valid_img_paths[:CFG.valid_bs * 3]\n",
        "    valid_msk_paths = valid_msk_paths[:CFG.valid_bs * 3]\n"
      ],
      "metadata": {
        "id": "WM6BbWfAugk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_dataset = BuildDataset(train_img_paths, train_msk_paths, transforms=data_transforms['train'])\n",
        "valid_dataset = BuildDataset(valid_img_paths, valid_msk_paths, transforms=data_transforms['valid'])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs, num_workers=3, shuffle=True, pin_memory=True, drop_last=False)\n",
        "\n",
        "# Ïù¥ÎØ∏ÏßÄÏùò Ï±ÑÎÑê ÏàòÎ•º 1Î°ú Î≥ÄÍ≤Ω\n",
        "for batch_idx, (batch_images, batch_mask) in enumerate(train_loader):\n",
        "    batch_images = torch.mean(batch_images.to(device), dim=1, keepdim=True)\n",
        "\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=CFG.valid_bs, num_workers=3, shuffle=False, drop_last=False)"
      ],
      "metadata": {
        "id": "PhKWozIeuhRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìà Visualization"
      ],
      "metadata": {
        "id": "vBonbtHAujwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, (batch_images, batch_mask) in enumerate(train_loader):\n",
        "    batch_images = torch.mean(batch_images, dim=1, keepdim=True)\n",
        "    print('Batch', batch_idx + 1)\n",
        "    print('Image batch shape:', batch_images.shape)\n",
        "    print('Label batch shape:', batch_mask.shape)\n",
        "\n",
        "    for image, mask, image_path, mask_path in zip(batch_images, batch_mask, train_img_paths, train_msk_paths):\n",
        "        image = image.permute((1,2,0)).numpy()*255.0\n",
        "        image = image.astype('uint8')\n",
        "\n",
        "        image_filename = os.path.basename(image_path)\n",
        "        mask_filename = os.path.basename(mask_path)\n",
        "\n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        plt.subplot(2,4,1)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title(f'Original Image - {image_filename}')\n",
        "\n",
        "        plt.subplot(2,4,2)\n",
        "        plt.imshow(mask, cmap='gray')\n",
        "        plt.title(f'Original Mask - {mask_filename}')\n",
        "        plt.show()\n",
        "    break"
      ],
      "metadata": {
        "id": "1aTpe3ogulgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "9OD4lzltunD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì¶ Model"
      ],
      "metadata": {
        "id": "G5M_0i77uqVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "def build_model():\n",
        "    model = smp.Unet(\n",
        "        encoder_name=CFG.backbone,      # encoder ÏÑ†ÌÉù, e.g. mobilenet_v2 or efficientnet-b7\n",
        "        encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
        "        in_channels=3,                  # Ïù∏Ìíã Ï±ÑÎÑê Ïàò (1 for gray-scale images, 3 for RGB, etc.)\n",
        "        classes=CFG.num_classes,        # ÏïÑÏõÉÌíã Ï±ÑÎÑê Ïàò (number of classes in your dataset)\n",
        "        activation=None,\n",
        "    )\n",
        "    model.to(CFG.device)\n",
        "    return model\n",
        "\n",
        "def load_model(path):\n",
        "    model = build_model()\n",
        "    model.load_state_dict(torch.load(path))\n",
        "    model.eval()  # Î™®Îç∏ÏùÑ ÌèâÍ∞ÄÎ™®ÎìúÎ°ú ÏÑ§Ï†ï\n",
        "    return model"
      ],
      "metadata": {
        "id": "yICzuXycusG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîß Loss Function"
      ],
      "metadata": {
        "id": "6RXXEPv7uss6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JaccardLoss = smp.losses.JaccardLoss(mode='binary')\n",
        "DiceLoss    = smp.losses.DiceLoss(mode='binary')\n",
        "BCELoss     = smp.losses.SoftBCEWithLogitsLoss()\n",
        "# LovaszLoss  = smp.losses.LovaszLoss(mode='multilabel', per_image=False)\n",
        "# verskyLoss = smp.losses.TverskyLoss(mode='multilabel', log_loss=False)\n",
        "\n",
        "import torch\n",
        "\n",
        "smooth = 1e-5\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_flat = y_true.view(-1)\n",
        "    y_pred_flat = y_pred.view(-1)\n",
        "\n",
        "    intersection = torch.sum(y_true_flat * y_pred_flat)\n",
        "\n",
        "    return (2 * intersection + smooth) / (torch.sum(y_true_flat) + torch.sum(y_pred_flat) + smooth)\n",
        "\n",
        "def iou_coef(y_true, y_pred, thr=0.5, dim=(2,3), epsilon=0.001):\n",
        "    y_true = y_true.to(torch.float32)\n",
        "    y_pred = (y_pred>thr).to(torch.float32)\n",
        "    inter = (y_true*y_pred).sum(dim=dim)\n",
        "    union = (y_true + y_pred - y_true*y_pred).sum(dim=dim)\n",
        "    iou = ((inter+epsilon)/(union+epsilon)).mean(dim=(1,0))\n",
        "    return iou\n",
        "\n",
        "def criterion(y_pred, y_true):\n",
        "    if CFG.loss_func == \"DiceLoss\":\n",
        "        return DiceLoss(y_pred, y_true)\n",
        "    elif CFG.loss_func == \"BCELoss\":\n",
        "        y_true = y_true.unsqueeze(1)\n",
        "        return BCELoss(y_pred, y_true)"
      ],
      "metadata": {
        "id": "1-qaDTdcutJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÑ Training Function"
      ],
      "metadata": {
        "id": "Rl2Z5xCFutdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Î™®Îç∏ train ÏúÑÌïú Ìï®Ïàò\n",
        "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
        "\n",
        "    model.train()  # Î™®Îç∏ÏùÑ ÌõàÎ†® Î™®ÎìúÎ°ú ÏÑ§Ï†ï\n",
        "    scaler = amp.GradScaler()  # Í∑∏ÎûòÎîîÏñ∏Ìä∏ Ïä§ÏºÄÏùºÎßÅÏùÑ ÏàòÌñâÌïòÍ∏∞ ÏúÑÌïú GradScaler Í∞ùÏ≤¥Î•º ÏÉùÏÑ±\n",
        "\n",
        "    # ÏóêÌè≠ Ï†ÑÏ≤¥Ïóê ÎåÄÌïú Ï¥ù Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞ Î∞è Îü¨Îãù ÏÜêÏã§ÏùÑ Ï¥àÍ∏∞Ìôî\n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
        "    for step, (images, masks) in pbar:\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        masks  = masks.to(device, dtype=torch.float)\n",
        "\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        with amp.autocast(enabled=True):  # Í∑∏ÎûòÎîîÏñ∏Ìä∏ Í≥ÑÏÇ∞ÏùÑ ÏàòÌñâÌïòÎäî Î≤îÏúÑÎ•º ÏßÄÏ†ï\n",
        "            # Î™®Îç∏ÏùÑ ÌÜµÌï¥ ÏòàÏ∏°ÏùÑ ÏàòÌñâÌïòÍ≥† ÏÜêÏã§ÏùÑ Í≥ÑÏÇ∞ & n_accumulateÏóê Îî∞Îùº Í≥ÑÏÇ∞Îêú ÏÜêÏã§ÏùÑ ÎÇòÎàÑÍ∏∞.\n",
        "            y_pred = model(images)\n",
        "            loss   = criterion(y_pred, masks)\n",
        "            loss   = loss / CFG.n_accumulate\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (step + 1) % CFG.n_accumulate == 0:  # ÏßÄÏ†ïÎêú n_accumulate Î∞∞ÏàòÎßàÎã§ Í∑∏ÎûòÎîîÏñ∏Ìä∏ ÏóÖÎç∞Ïù¥Ìä∏Î•º ÏàòÌñâ\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = running_loss / dataset_size  # ÏóêÌè≠ Ï†ÑÏ≤¥Ïóê ÎåÄÌïú ÌèâÍ∑† ÏÜêÏã§ÏùÑ Í≥ÑÏÇ∞\n",
        "\n",
        "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        pbar.set_postfix( epoch=f'{epoch}',\n",
        "                          train_loss=f'{epoch_loss:0.4f}',\n",
        "                          lr=f'{current_lr:0.5f}',\n",
        "                          gpu_mem=f'{mem:0.2f} GB')\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "T1kbWrJZut4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üëÄ Validation Function"
      ],
      "metadata": {
        "id": "stLU9eKUuumC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()  # Ìï¥Îãπ Ìï®Ïàò ÎÇ¥ÏóêÏÑú Í∑∏ÎûòÎîîÏñ∏Ìä∏Î•º Ï∂îÏ†ÅÌïòÏßÄ ÏïäÎèÑÎ°ù ÏÑ§Ï†ï -> ÌèâÍ∞Ä ÏãúÏóêÎäî ÌïÑÏöî ÏóÜÍ∏∞ ÎïåÎ¨∏\n",
        "\n",
        "def valid_one_epoch(model, dataloader, device, epoch):\n",
        "    model.eval()\n",
        "\n",
        "    dataset_size = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    val_scores = []\n",
        "\n",
        "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid')\n",
        "\n",
        "    for step, (images, masks) in pbar:\n",
        "        images  = images.to(device, dtype=torch.float)\n",
        "        masks   = masks.to(device, dtype=torch.float)\n",
        "\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        y_pred  = model(images)\n",
        "        loss    = criterion(y_pred, masks)\n",
        "\n",
        "        running_loss += (loss.item() * batch_size)\n",
        "        dataset_size += batch_size\n",
        "\n",
        "        epoch_loss = running_loss / dataset_size\n",
        "\n",
        "        y_pred = nn.Sigmoid()(y_pred)\n",
        "        val_dice = dice_coef(masks, y_pred).cpu().detach().numpy()\n",
        "        val_jaccard = iou_coef(masks, y_pred).cpu().detach().numpy()\n",
        "        val_scores.append([val_dice, val_jaccard])\n",
        "\n",
        "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
        "                        lr=f'{current_lr:0.5f}',\n",
        "                        gpu_memory=f'{mem:0.2f} GB')\n",
        "    val_scores  = np.mean(val_scores, axis=0)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return epoch_loss, val_scores"
      ],
      "metadata": {
        "id": "zps-T9bYuuvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèÉ Run Training"
      ],
      "metadata": {
        "id": "4Bjn8H9buu3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
        "    # To automatically log gradients\n",
        "#     wandb.watch(model, log_freq=100)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(\"cuda: {}\\n\".format(torch.cuda.get_device_name()))\n",
        "\n",
        "    start = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_dice      = np.inf\n",
        "    best_epoch     = -1\n",
        "    history = defaultdict(list)\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        gc.collect()\n",
        "        print(f'Epoch {epoch}/{num_epochs}', end='')\n",
        "        train_loss = train_one_epoch(model, optimizer, scheduler,\n",
        "                                           dataloader=train_loader,\n",
        "                                           device=CFG.device, epoch=epoch)\n",
        "\n",
        "        val_loss, val_scores = valid_one_epoch(model, valid_loader,\n",
        "                                                 device=CFG.device,\n",
        "                                                 epoch=epoch)\n",
        "        val_dice, val_jaccard = val_scores\n",
        "\n",
        "        history['Train Loss'].append(train_loss)\n",
        "        history['Valid Loss'].append(val_loss)\n",
        "        history['Valid Dice'].append(val_dice)\n",
        "        history['Valid Jaccard'].append(val_jaccard)\n",
        "\n",
        "        # Log the metrics\n",
        "#         wandb.log({\"Train Loss\": train_loss,\n",
        "#                    \"Valid Loss\": val_loss,\n",
        "#                    \"Valid Dice\": val_dice,\n",
        "#                    \"Valid Jaccard\": val_jaccard,\n",
        "#                    \"LR\":scheduler.get_last_lr()[0]})\n",
        "\n",
        "#         print(f'Valid Dice: {val_dice:0.4f} | Valid Jaccard: {val_jaccard:0.4f}')\n",
        "\n",
        "        # deep copy the model\n",
        "        if val_dice >= best_dice:\n",
        "            print(f\"{c_}Valid Score Improved ({best_dice:0.4f} ---> {val_dice:0.4f})\")\n",
        "            best_dice    = val_dice\n",
        "            best_jaccard = val_jaccard\n",
        "            best_epoch   = epoch\n",
        "            run.summary[\"Best Dice\"]    = best_dice\n",
        "            run.summary[\"Best Jaccard\"] = best_jaccard\n",
        "            run.summary[\"Best Epoch\"]   = best_epoch\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            PATH = f\"best_epoch-{fold:02d}.bin\"\n",
        "            torch.save(model.state_dict(), PATH)\n",
        "            # Save a model file from the current directory\n",
        "#             wandb.save(PATH)\n",
        "            print(f\"Model Saved{sr_}\")\n",
        "\n",
        "        last_model_wts = copy.deepcopy(model.state_dict())\n",
        "        PATH = f'/content/drive/MyDrive/Final_Project/blood-vessel-segmentation/model_weights.pth'\n",
        "        torch.save(model.state_dict(), PATH)\n",
        "\n",
        "        print(); print()\n",
        "\n",
        "    end = time.time()\n",
        "    time_elapsed = end - start\n",
        "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
        "    print(\"Best Score: {:.4f}\".format(best_jaccard))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, history"
      ],
      "metadata": {
        "id": "0k1xsEzMu7Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîç Optimizer"
      ],
      "metadata": {
        "id": "cVQNA694u9fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_scheduler(optimizer):\n",
        "    if CFG.scheduler == 'CosineAnnealingLR':\n",
        "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CFG.T_max,\n",
        "                                                   eta_min=CFG.min_lr)\n",
        "    elif CFG.scheduler == 'CosineAnnealingWarmRestarts':\n",
        "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CFG.T_0,\n",
        "                                                             eta_min=CFG.min_lr)\n",
        "    elif CFG.scheduler == 'ReduceLROnPlateau':\n",
        "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                   mode='min',\n",
        "                                                   factor=0.1,\n",
        "                                                   patience=7,\n",
        "                                                   threshold=0.0001,\n",
        "                                                   min_lr=CFG.min_lr,)\n",
        "    elif CFG.scheduer == 'ExponentialLR':\n",
        "        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n",
        "    elif CFG.scheduler == None:\n",
        "        return None\n",
        "\n",
        "    return scheduler\n",
        "\n",
        "def select_optimizer():\n",
        "    if CFG.optimizers == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
        "\n",
        "    elif CFG.optimizers == 'nadam':\n",
        "        optimizer = optim.NAdam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
        "\n",
        "    elif CFG.optimizers == 'adamW':\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
        "\n",
        "    elif CFG.optimizers == 'sgd':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
        "\n",
        "    elif CFG.optimizers ==None:\n",
        "        return None\n",
        "\n",
        "    return optimizer"
      ],
      "metadata": {
        "id": "9-Bnz8dHvBJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "optimizer = optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n",
        "optimizer = select_optimizer()\n",
        "scheduler = fetch_scheduler(optimizer)"
      ],
      "metadata": {
        "id": "JhCgYCHEvBsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üöÖ Training"
      ],
      "metadata": {
        "id": "nIJBHRCivEwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model, history = run_training(model, optimizer, scheduler,\n",
        "                                device=CFG.device,\n",
        "                                num_epochs=CFG.epochs)"
      ],
      "metadata": {
        "id": "RVBZb_fOvGmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî≠ Prediction"
      ],
      "metadata": {
        "id": "sDoZMyijvIHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame(data={'test':test_images})\n",
        "test_dataset = BuildDataset(test_df['test'], label=False,\n",
        "                            transforms=data_transforms['valid'])\n",
        "test_loader  = DataLoader(test_dataset, batch_size=5,\n",
        "                          num_workers=4, shuffle=False, pin_memory=True)\n",
        "imgs = next(iter(test_loader))\n",
        "imgs = imgs.to(CFG.device, dtype=torch.float)\n",
        "\n",
        "preds = []\n",
        "for fold in range(1):\n",
        "    model = load_model(f\"best_epoch-{fold:02d}.bin\")\n",
        "    with torch.no_grad():\n",
        "        pred = model(imgs)\n",
        "        pred = (nn.Sigmoid()(pred)>0.5).double()\n",
        "    preds.append(pred)\n",
        "\n",
        "imgs  = imgs.cpu().detach()\n",
        "preds = torch.mean(torch.stack(preds, dim=0), dim=0).cpu().detach()"
      ],
      "metadata": {
        "id": "xKgl-JucvIiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img(img, mask=None):\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    img = clahe.apply(img)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(img, cmap='bone')\n",
        "\n",
        "    if mask is not None:\n",
        "        # plt.imshow(np.ma.masked_where(mask!=1, mask), alpha=0.5, cmap='autumn')\n",
        "        plt.imshow(mask, alpha=0.5)\n",
        "        handles = [Rectangle((0,0),1,1, color=_c) for _c in [(0.667,0.0,0.0), (0.0,0.667,0.0), (0.0,0.0,0.667)]]\n",
        "        labels = [\"Large Bowel\", \"Small Bowel\", \"Stomach\"]\n",
        "        plt.legend(handles,labels)\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "FAq0RZ5z1zsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_batch(imgs, msks, size=3):\n",
        "    plt.figure(figsize=(5*5, 5))\n",
        "    for idx in range(size):\n",
        "        plt.subplot(1, 5, idx+1)\n",
        "        img = imgs[idx,].permute((1, 2, 0)).numpy()*255.0\n",
        "        img = img.astype('uint8')\n",
        "        msk = msks[idx,].permute((1, 2, 0)).numpy()*255.0\n",
        "        show_img(img, msk)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6NnutDsv1oYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_batch(imgs, preds, size=5)"
      ],
      "metadata": {
        "id": "iJCNNEsRvLWB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}